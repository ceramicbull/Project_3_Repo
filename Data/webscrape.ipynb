{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests \n",
    "import time\n",
    "import os\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with list of tables\n",
    "url=\"https://nuforc.org/webreports/ndxloc.html\"\n",
    "#tables to skip:\n",
    "skip_list=['INTERNATIONAL',\n",
    "           'ALBERTA',\n",
    "           'BRITISH COLUMBIA',\n",
    "           'MANITOBA',\n",
    "           'NEW BRUNSWICK',\n",
    "           'NEWFOUNDLAND',\n",
    "           'NEWFOUNDLAND AND LABRADOR',\n",
    "           'NORTHWEST TERRITORY',\n",
    "           'NOVA SCOTIA',\n",
    "           'ONTARIO',\n",
    "           'PRINCE EDW ISLAND',\n",
    "           'PROV OF QUE',\n",
    "           'SASKATCHEWAN',\n",
    "           'YUKON']\n",
    "#blank master df\n",
    "master_df=pd.DataFrame(columns=['Date / Time',\n",
    "                                'City','State',\n",
    "                                'Shape','Duration',\n",
    "                                'Summary',\n",
    "                                'Link to Event'])\n",
    "master_df['Date / Time']=pd.to_datetime(master_df['Date / Time'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load browser\n",
    "browser = Browser('chrome', executable_path=ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start souping\n",
    "\n",
    "html = browser.html\n",
    "_soup= soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"ndxlAL.html\">ALABAMA</a>, <a href=\"ndxlAK.html\">ALASKA</a>, <a href=\"ndxlAZ.html\">ARIZONA</a>, <a href=\"ndxlAR.html\">ARKANSAS</a>, <a href=\"ndxlCA.html\">CALIFORNIA</a>, <a href=\"ndxlCO.html\">COLORADO</a>, <a href=\"ndxlCT.html\">CONNECTICUT</a>, <a href=\"ndxlDE.html\">DELAWARE</a>, <a href=\"ndxlDC.html\">DISTRICT OF COLUMBIA</a>, <a href=\"ndxlFL.html\">FLORIDA</a>, <a href=\"ndxlGA.html\">GEORGIA</a>, <a href=\"ndxlHI.html\">HAWAII</a>, <a href=\"ndxlID.html\">IDAHO</a>, <a href=\"ndxlIL.html\">ILLINOIS</a>, <a href=\"ndxlIN.html\">INDIANA</a>, <a href=\"ndxlIA.html\">IOWA</a>, <a href=\"ndxlKS.html\">KANSAS</a>, <a href=\"ndxlKY.html\">KENTUCKY</a>, <a href=\"ndxlLA.html\">LOUISIANA</a>, <a href=\"ndxlME.html\">MAINE</a>, <a href=\"ndxlMD.html\">MARYLAND</a>, <a href=\"ndxlMA.html\">MASSACHUSETTS</a>, <a href=\"ndxlMI.html\">MICHIGAN</a>, <a href=\"ndxlMN.html\">MINNESOTA</a>, <a href=\"ndxlMS.html\">MISSISSIPPI</a>, <a href=\"ndxlMO.html\">MISSOURI</a>, <a href=\"ndxlMT.html\">MONTANA</a>, <a href=\"ndxlNE.html\">NEBRASKA</a>, <a href=\"ndxlNV.html\">NEVADA</a>, <a href=\"ndxlNH.html\">NEW HAMPSHIRE</a>, <a href=\"ndxlNJ.html\">NEW JERSEY</a>, <a href=\"ndxlNM.html\">NEW MEXICO</a>, <a href=\"ndxlNY.html\">NEW YORK</a>, <a href=\"ndxlNC.html\">NORTH CAROLINA</a>, <a href=\"ndxlND.html\">NORTH DAKOTA</a>, <a href=\"ndxlOH.html\">OHIO</a>, <a href=\"ndxlOK.html\">OKLAHOMA</a>, <a href=\"ndxlOR.html\">OREGON</a>, <a href=\"ndxlPA.html\">PENNSYLVANIA</a>, <a href=\"ndxlRI.html\">RHODE ISLAND</a>, <a href=\"ndxlSC.html\">SOUTH CAROLINA</a>, <a href=\"ndxlSD.html\">SOUTH DAKOTA</a>, <a href=\"ndxlTN.html\">TENNESSEE</a>, <a href=\"ndxlTX.html\">TEXAS</a>, <a href=\"ndxlUT.html\">UTAH</a>, <a href=\"ndxlVT.html\">VERMONT</a>, <a href=\"ndxlVA.html\">VIRGINIA</a>, <a href=\"ndxlWA.html\">WASHINGTON</a>, <a href=\"ndxlWV.html\">WEST VIRGINIA</a>, <a href=\"ndxlWI.html\">WISCONSIN</a>, <a href=\"ndxlWY.html\">WYOMING</a>, <a href=\"ndxlINTERNATIONAL.html\">INTERNATIONAL</a>, <a href=\"ndxlAB.html\">ALBERTA</a>, <a href=\"ndxlBC.html\">BRITISH COLUMBIA</a>, <a href=\"ndxlMB.html\">MANITOBA</a>, <a href=\"ndxlNB.html\">NEW BRUNSWICK</a>, <a href=\"ndxlNF.html\">NEWFOUNDLAND</a>, <a href=\"ndxlNF.html\">NEWFOUNDLAND AND LABRADOR</a>, <a href=\"ndxlNT.html\">NORTHWEST TERRITORY</a>, <a href=\"ndxlNS.html\">NOVA SCOTIA</a>, <a href=\"ndxlON.html\">ONTARIO</a>, <a href=\"ndxlPE.html\">PRINCE EDW ISLAND</a>, <a href=\"ndxlPQ.html\">PROV OF QUE</a>, <a href=\"ndxlSA.html\">SASKATCHEWAN</a>, <a href=\"ndxlYK.html\">YUKON</a>]\n"
     ]
    }
   ],
   "source": [
    "#drill down to list of state tables\n",
    "table=_soup.find('tbody')\n",
    "#list of tables\n",
    "links=table.find_all('a')\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date / Time</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Link to Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-14 21:55:00</td>\n",
       "      <td>Deer Park</td>\n",
       "      <td>AL</td>\n",
       "      <td>Circle</td>\n",
       "      <td>About 30 mins</td>\n",
       "      <td>Flashing circle/ fire colored/ torpedo</td>\n",
       "      <td>https://nuforc.org/webreports/reports/175/S175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-14 20:40:00</td>\n",
       "      <td>Athens</td>\n",
       "      <td>AL</td>\n",
       "      <td>Circle</td>\n",
       "      <td>About 2 seconds</td>\n",
       "      <td>Huge yellow-white sphere 5 times the size of t...</td>\n",
       "      <td>https://nuforc.org/webreports/reports/175/S175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-13 21:30:00</td>\n",
       "      <td>Pike Road</td>\n",
       "      <td>AL</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hours</td>\n",
       "      <td>Tatyana Bakieva</td>\n",
       "      <td>https://nuforc.org/webreports/reports/175/S175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-02 04:46:00</td>\n",
       "      <td>Falkville</td>\n",
       "      <td>AL</td>\n",
       "      <td>Light</td>\n",
       "      <td>About 10 minutes</td>\n",
       "      <td>Lights that traveled across the sky faster tha...</td>\n",
       "      <td>https://nuforc.org/webreports/reports/175/S175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-01 03:32:00</td>\n",
       "      <td>Grand Bay</td>\n",
       "      <td>AL</td>\n",
       "      <td>Sphere</td>\n",
       "      <td>Five to ten minutes</td>\n",
       "      <td>Was looking at stars in the Northern sky and s...</td>\n",
       "      <td>https://nuforc.org/webreports/reports/175/S175...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date / Time       City State   Shape             Duration  \\\n",
       "0 2023-05-14 21:55:00  Deer Park    AL  Circle        About 30 mins   \n",
       "1 2023-05-14 20:40:00     Athens    AL  Circle      About 2 seconds   \n",
       "2 2023-05-13 21:30:00  Pike Road    AL  Circle                Hours   \n",
       "3 2023-05-02 04:46:00  Falkville    AL   Light     About 10 minutes   \n",
       "4 2023-05-01 03:32:00  Grand Bay    AL  Sphere  Five to ten minutes   \n",
       "\n",
       "                                             Summary  \\\n",
       "0             Flashing circle/ fire colored/ torpedo   \n",
       "1  Huge yellow-white sphere 5 times the size of t...   \n",
       "2                                    Tatyana Bakieva   \n",
       "3  Lights that traveled across the sky faster tha...   \n",
       "4  Was looking at stars in the Northern sky and s...   \n",
       "\n",
       "                                       Link to Event  \n",
       "0  https://nuforc.org/webreports/reports/175/S175...  \n",
       "1  https://nuforc.org/webreports/reports/175/S175...  \n",
       "2  https://nuforc.org/webreports/reports/175/S175...  \n",
       "3  https://nuforc.org/webreports/reports/175/S175...  \n",
       "4  https://nuforc.org/webreports/reports/175/S175...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Debug Cell\n",
    "demo_df=pd.DataFrame(columns=['Date / Time','City','State','Shape','Duration','Summary','Link to Event'])\n",
    "demo_df['Date / Time']=pd.to_datetime(demo_df['Date / Time'],errors='coerce')\n",
    "page=links[0].get('href')\n",
    "state=links[0].text\n",
    "table_url=f'https://nuforc.org/webreports/{page}'\n",
    "df=pd.read_html(table_url)[0]\n",
    "clean_df=df.drop(columns=['Country','Posted','Images'])\n",
    "#clean_df.head()\n",
    "browser.visit(table_url)\n",
    "tab_html = browser.html\n",
    "tab_soup= soup(tab_html, 'html.parser')\n",
    "tab_tab=tab_soup.find('tbody')\n",
    "tab_link=tab_tab.find_all('a')\n",
    "link_list=[]\n",
    "for link in tab_link:\n",
    "    href=link.get('href')\n",
    "    href_url=f'https://nuforc.org/webreports/{href}'\n",
    "    link_list.append(href_url)\n",
    "clean_df['Link to Event']=link_list\n",
    "clean_df['Date / Time']=pd.to_datetime(clean_df['Date / Time'],errors='coerce')\n",
    "filter_df=clean_df.loc[clean_df['Date / Time']>=\"2013-1-1\"]\n",
    "filter_df\n",
    "demo_df=pd.concat([demo_df,filter_df])\n",
    "demo_df.head()\n",
    "\n",
    "#df.to_csv(f\"output_csv/{state}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date / Time      datetime64[ns]\n",
       "City                     object\n",
       "State                    object\n",
       "Shape                    object\n",
       "Duration                 object\n",
       "Summary                  object\n",
       "Link to Event            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Debug Cell 2\n",
    "demo_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ALABAMA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting ALABAMA.csv\n",
      "Concatenating ALABAMA info to Master csv\n",
      "Working on ALASKA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting ALASKA.csv\n",
      "Concatenating ALASKA info to Master csv\n",
      "Working on ARIZONA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting ARIZONA.csv\n",
      "Concatenating ARIZONA info to Master csv\n",
      "Working on ARKANSAS table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting ARKANSAS.csv\n",
      "Concatenating ARKANSAS info to Master csv\n",
      "Working on CALIFORNIA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting CALIFORNIA.csv\n",
      "Concatenating CALIFORNIA info to Master csv\n",
      "Working on COLORADO table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting COLORADO.csv\n",
      "Concatenating COLORADO info to Master csv\n",
      "Working on CONNECTICUT table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting CONNECTICUT.csv\n",
      "Concatenating CONNECTICUT info to Master csv\n",
      "Working on DELAWARE table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting DELAWARE.csv\n",
      "Concatenating DELAWARE info to Master csv\n",
      "Working on DISTRICT OF COLUMBIA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting DISTRICT OF COLUMBIA.csv\n",
      "Concatenating DISTRICT OF COLUMBIA info to Master csv\n",
      "Working on FLORIDA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting FLORIDA.csv\n",
      "Concatenating FLORIDA info to Master csv\n",
      "Working on GEORGIA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting GEORGIA.csv\n",
      "Concatenating GEORGIA info to Master csv\n",
      "Working on HAWAII table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting HAWAII.csv\n",
      "Concatenating HAWAII info to Master csv\n",
      "Working on IDAHO table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting IDAHO.csv\n",
      "Concatenating IDAHO info to Master csv\n",
      "Working on ILLINOIS table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting ILLINOIS.csv\n",
      "Concatenating ILLINOIS info to Master csv\n",
      "Working on INDIANA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting INDIANA.csv\n",
      "Concatenating INDIANA info to Master csv\n",
      "Working on IOWA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting IOWA.csv\n",
      "Concatenating IOWA info to Master csv\n",
      "Working on KANSAS table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting KANSAS.csv\n",
      "Concatenating KANSAS info to Master csv\n",
      "Working on KENTUCKY table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting KENTUCKY.csv\n",
      "Concatenating KENTUCKY info to Master csv\n",
      "Working on LOUISIANA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting LOUISIANA.csv\n",
      "Concatenating LOUISIANA info to Master csv\n",
      "Working on MAINE table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MAINE.csv\n",
      "Concatenating MAINE info to Master csv\n",
      "Working on MARYLAND table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MARYLAND.csv\n",
      "Concatenating MARYLAND info to Master csv\n",
      "Working on MASSACHUSETTS table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MASSACHUSETTS.csv\n",
      "Concatenating MASSACHUSETTS info to Master csv\n",
      "Working on MICHIGAN table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MICHIGAN.csv\n",
      "Concatenating MICHIGAN info to Master csv\n",
      "Working on MINNESOTA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MINNESOTA.csv\n",
      "Concatenating MINNESOTA info to Master csv\n",
      "Working on MISSISSIPPI table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MISSISSIPPI.csv\n",
      "Concatenating MISSISSIPPI info to Master csv\n",
      "Working on MISSOURI table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MISSOURI.csv\n",
      "Concatenating MISSOURI info to Master csv\n",
      "Working on MONTANA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting MONTANA.csv\n",
      "Concatenating MONTANA info to Master csv\n",
      "Working on NEBRASKA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NEBRASKA.csv\n",
      "Concatenating NEBRASKA info to Master csv\n",
      "Working on NEVADA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NEVADA.csv\n",
      "Concatenating NEVADA info to Master csv\n",
      "Working on NEW HAMPSHIRE table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NEW HAMPSHIRE.csv\n",
      "Concatenating NEW HAMPSHIRE info to Master csv\n",
      "Working on NEW JERSEY table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NEW JERSEY.csv\n",
      "Concatenating NEW JERSEY info to Master csv\n",
      "Working on NEW MEXICO table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NEW MEXICO.csv\n",
      "Concatenating NEW MEXICO info to Master csv\n",
      "Working on NEW YORK table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NEW YORK.csv\n",
      "Concatenating NEW YORK info to Master csv\n",
      "Working on NORTH CAROLINA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NORTH CAROLINA.csv\n",
      "Concatenating NORTH CAROLINA info to Master csv\n",
      "Working on NORTH DAKOTA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting NORTH DAKOTA.csv\n",
      "Concatenating NORTH DAKOTA info to Master csv\n",
      "Working on OHIO table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting OHIO.csv\n",
      "Concatenating OHIO info to Master csv\n",
      "Working on OKLAHOMA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting OKLAHOMA.csv\n",
      "Concatenating OKLAHOMA info to Master csv\n",
      "Working on OREGON table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting OREGON.csv\n",
      "Concatenating OREGON info to Master csv\n",
      "Working on PENNSYLVANIA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting PENNSYLVANIA.csv\n",
      "Concatenating PENNSYLVANIA info to Master csv\n",
      "Working on RHODE ISLAND table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting RHODE ISLAND.csv\n",
      "Concatenating RHODE ISLAND info to Master csv\n",
      "Working on SOUTH CAROLINA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting SOUTH CAROLINA.csv\n",
      "Concatenating SOUTH CAROLINA info to Master csv\n",
      "Working on SOUTH DAKOTA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting SOUTH DAKOTA.csv\n",
      "Concatenating SOUTH DAKOTA info to Master csv\n",
      "Working on TENNESSEE table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting TENNESSEE.csv\n",
      "Concatenating TENNESSEE info to Master csv\n",
      "Working on TEXAS table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting TEXAS.csv\n",
      "Concatenating TEXAS info to Master csv\n",
      "Working on UTAH table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting UTAH.csv\n",
      "Concatenating UTAH info to Master csv\n",
      "Working on VERMONT table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting VERMONT.csv\n",
      "Concatenating VERMONT info to Master csv\n",
      "Working on VIRGINIA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting VIRGINIA.csv\n",
      "Concatenating VIRGINIA info to Master csv\n",
      "Working on WASHINGTON table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting WASHINGTON.csv\n",
      "Concatenating WASHINGTON info to Master csv\n",
      "Working on WEST VIRGINIA table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting WEST VIRGINIA.csv\n",
      "Concatenating WEST VIRGINIA info to Master csv\n",
      "Working on WISCONSIN table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting WISCONSIN.csv\n",
      "Concatenating WISCONSIN info to Master csv\n",
      "Working on WYOMING table.\n",
      "dropping columns\n",
      "getting links\n",
      "Processing hrefs\n",
      "processing Date/Time\n",
      "Exporting WYOMING.csv\n",
      "Concatenating WYOMING info to Master csv\n",
      "Skipping INTERNATIONAL.\n",
      "Skipping ALBERTA.\n",
      "Skipping BRITISH COLUMBIA.\n",
      "Skipping MANITOBA.\n",
      "Skipping NEW BRUNSWICK.\n",
      "Skipping NEWFOUNDLAND.\n",
      "Skipping NEWFOUNDLAND AND LABRADOR.\n",
      "Skipping NORTHWEST TERRITORY.\n",
      "Skipping NOVA SCOTIA.\n",
      "Skipping ONTARIO.\n",
      "Skipping PRINCE EDW ISLAND.\n",
      "Skipping PROV OF QUE.\n",
      "Skipping SASKATCHEWAN.\n",
      "Skipping YUKON.\n"
     ]
    }
   ],
   "source": [
    "#loop through the links on the page\n",
    "for link in links:\n",
    "    #get relevant info and construct url\n",
    "    page=link.get('href')\n",
    "    state=link.text\n",
    "    table_url=f'https://nuforc.org/webreports/{page}'\\\n",
    "    #check to make sure table is not international\n",
    "    if state in skip_list:\n",
    "        #if international, just print that the program is skipping it\n",
    "        print(f\"Skipping {state}.\")\n",
    "        time.sleep(.1) \n",
    "    else:\n",
    "        #inform user that program is processing a given state\n",
    "        print(f\"Working on {state} table.\")\n",
    "        #read in info with pandas read_html\n",
    "        df=pd.read_html(table_url)[0]\n",
    "        #drop unnecessary columns\n",
    "        print(f\"dropping columns\")\n",
    "        clean_df=df.drop(columns=['Country','Posted','Images'])\n",
    "        #obtain links to events\n",
    "        print(f\"getting links\")\n",
    "        #direct browser and drill down through html\n",
    "        browser.visit(table_url)\n",
    "        tab_html = browser.html\n",
    "        tab_soup= soup(tab_html, 'html.parser')\n",
    "        tab_tab=tab_soup.find('tbody')\n",
    "        #scrape list of html links\n",
    "        tab_link=tab_tab.find_all('a')\n",
    "        #generate blank list for holding urls\n",
    "        print(f\"Processing hrefs\")\n",
    "        url_list=[]\n",
    "        for link in tab_link:\n",
    "            href=link.get('href')\n",
    "            href_url=f'https://nuforc.org/webreports/{href}'\n",
    "            url_list.append(href_url)\n",
    "        #append the url list as a new column to df\n",
    "        clean_df['Link to Event']=url_list\n",
    "        #convert Date/Time to Datetime dtype\n",
    "        print(f\"processing Date/Time\")\n",
    "        clean_df['Date / Time']=pd.to_datetime(clean_df['Date / Time'],errors='coerce')\n",
    "        #filter info down to last 10 years\n",
    "        filter_df=clean_df.loc[clean_df['Date / Time']>=\"2013-1-1\"]\n",
    "        #output csv\n",
    "        print(f\"Exporting {state}.csv\")\n",
    "        filter_df.to_csv(f\"output_csv/{state}.csv\")\n",
    "        #concatenate data to master csv\n",
    "        print(f\"Concatenating {state} info to Master csv\")\n",
    "        master_df=pd.concat([master_df,filter_df])\n",
    "        time.sleep(.1) \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export master csv\n",
    "master_df.to_csv(f\"output_csv/USA.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseWebDriver.quit of <splinter.driver.webdriver.chrome.WebDriver object at 0x000002909E26AD60>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.quit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
